{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"Evaluation Pipelines.ipynb","provenance":[],"collapsed_sections":["oI3yo6BFPa7N"]}},"cells":[{"cell_type":"markdown","metadata":{"id":"zJ_LlOnpPa69"},"source":["# Short Story Generator: Evaluation Pipelines"]},{"cell_type":"markdown","metadata":{"id":"AKlx-BPStzRc"},"source":["This is a top-level (i.e. it can be executed by the user) notebook that makes use of (calls) many other notebooks and files. The files (data) is shared using GDrive and the other notebooks using GitHub. To connect to these external sources, it is thus imperrative that Steps 0 to 7 (contained under the **Load libraries & connect to code and data** heading) are followed first.\n","\n","If the user wants to investigate the code (annotated notebooks) called by this notebook, they can also be opened in Google Colab:\n","\n","File > Open notebook > GitHub > https://github.com/frau-web/nlp_short_story_generator.git\n","\n","---\n","\n","This specific notebook (in the section titled **Evaluation Grid Creation**)collects all trained Story Generating Models and creates a grid of stories generated using different combinations of models, training data, generated story lengths and seed sentences.\n","\n","---\n","\n","Next (in the **Manual Rating** section), this grid can be evaluated by users.\n","\n","---\n","\n","Lastly (as contained in the **Rating Analysis** section), these manual ratings are analysed.\n","\n","---\n","In summary, all users must follow all steps in the **Load libraries & connect \n","to code and data** section, but can then skip the any other relevant section.\n","\n","---\n"]},{"cell_type":"markdown","metadata":{"id":"bva_JtgCPeXY"},"source":["## Load libraries & connect to code and data"]},{"cell_type":"markdown","metadata":{"id":"l7ejCVq0rKwB"},"source":["**Step 0:** Please run the following cell to load the required libraries and then follow Steps 1-5 and 6-7 to connect with and download, respectively, the data and additional code this notebook requires to function."]},{"cell_type":"code","metadata":{"id":"ZDVhH-RUriDt"},"source":["from IPython.display import clear_output\n","from google.colab import drive\n","import pandas as pd\n","import time"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HU51triAP0AY"},"source":["### Data from GDrive"]},{"cell_type":"markdown","metadata":{"id":"VuyxnILUcF8U"},"source":["**Step 1:** Please navigate to the shared folder on GDrive, named \"data\" that contains the project's data and select \"Add a shortcut to Drive\" to add a shortcut of the folder to YOUR GDrive."]},{"cell_type":"markdown","metadata":{"id":"TkrIIJpOfP3x"},"source":["**Step 2:** Please mount YOUR GDrive:"]},{"cell_type":"code","metadata":{"id":"0miRy0_7P3VK"},"source":["drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wuxmxv4wfWli"},"source":["**Step 3:** By using the \"Files\" tab in the Left-hand Sidebar of Colab, please navigate to the \"data\" (shortcut) folder that you created in Step 1 and, from the menu that appears when you click on the three dots next to \"data\", select \"Copy path\"."]},{"cell_type":"markdown","metadata":{"id":"7dRKzMLBgvm4"},"source":["**Step 4:** Please run the following cell and paste that path when prompted:"]},{"cell_type":"code","metadata":{"id":"K86y66ZSQB71"},"source":["data_path = input(\"Please paste the path to the 'data' folder as copied from the Colab files tab.\") + \"/\"\n","clear_output()\n","data_path"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o-r65X10g7Cd"},"source":["**Step 5:** Lastly, please test the connection using the following cell. If the output is not ``` evaluation/ models/  stories/```\n","then the connection was not made correctly and the steps should be followed again.\n"]},{"cell_type":"code","metadata":{"id":"hExza-m1hTXS"},"source":["%cd $data_path\n","clear_output()\n","%ls"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JDNBoZKRPqSZ"},"source":["### Code from GitHub"]},{"cell_type":"markdown","metadata":{"id":"S0QH8S19nNR8"},"source":["**Step 6:** Please clone the GitHub repository by executing the cell below:"]},{"cell_type":"code","metadata":{"id":"EqGxx6j-llIL"},"source":["github_path = \"/content/github\"\n","%mkdir $github_path\n","%cd $github_path\n","! git clone https://github.com/frau-web/nlp_short_story_generator.git\n","code_path = \"/content/github/nlp_short_story_generator\"\n","%cd $code_path"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WGo4zoaBoL2w"},"source":["**Step 7:** Lastly, please confirm the propper execution of Step 6 by using the following cell. \n","\n","If the output is not ```data/  evaluation/  generation/  ReadME.md``` then Step 6 was not executed correctly."]},{"cell_type":"code","metadata":{"id":"WaFM0vS3oT27"},"source":["%ls"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NQJU5vJu1Le4"},"source":["## Evaluation Grid Creation"]},{"cell_type":"markdown","metadata":{"id":"ISV0Qpx0Pa7H"},"source":["### Input options"]},{"cell_type":"code","metadata":{"id":"smloZ2EAPa7H"},"source":["def gen_seed_sentence(seed_sentence_type):\n","  if seed_sentence_type == \"constructed\":\n","    return \"Anthea and Robert were in London.\" #See POS&NER.ipynb in 'nlp_short_story_generator/data'\n","  else:\n","    return \"Once upon a time\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t9xbSOGnPa7H"},"source":["### Load Model Functions"]},{"cell_type":"markdown","metadata":{"id":"U4heMMQDRRqf"},"source":["These notebooks must be executed in the order specified below and can only be executed once."]},{"cell_type":"code","metadata":{"id":"zkjhHPZDOF4-"},"source":["%run ./generation/generator_gpt2_simple.ipynb"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jqnNd9IMAa33"},"source":["training_stories_filename = \"input_stories_toddlerpluschildren.txt\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P5Qhn6Rt-a7w"},"source":["%run ./generation/generator_ngram_6.ipynb"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CgBwDeSLEVNp"},"source":["%run ./generation/generator_ngram_4.ipynb"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sNd7myV-Pa7I"},"source":["%run ./generation/generator_gpt2.ipynb"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QbRX07NXBxU8"},"source":["%run ./generation/generator_gpt2_tuned.ipynb"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W_-baomzt9Je"},"source":["%run ./generation/generator_gpt2_tuned_unfrozen.ipynb"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kO8ExqHDPa7I"},"source":["### Post-processing"]},{"cell_type":"code","metadata":{"id":"BIwVUKNMPa7J"},"source":["def post_proc(raw_story):\n","  if raw_story == \"\":\n","    proc_story = \"### STORY COULD NOT BE GENERATED ###\"\n","  else:\n","    proc_story = raw_story\n","    \n","  return raw_story"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V2xhRxVXPa7J"},"source":["### Model Prediction Pipeline"]},{"cell_type":"code","metadata":{"id":"lNk-4JByPa7J"},"source":["def compose_story(model, training_set, seed_sentence, max_length):\n","    start_time = time.time()\n","    seed_sentence = gen_seed_sentence(seed_sentence)\n","\n","    if model == \"ngram_4\" and training_set == \"T&C\":\n","      raw_output = generate_text4(seed=seed_sentence, numwords=max_length)\n","    elif model == \"ngram_6\" and training_set == \"T&C\":\n","      raw_output = generate_text6(seed=seed_sentence, numwords=max_length)\n","    elif model == 'gpt2':\n","      raw_output = gen_story(my_model=gpt2, seed=seed_sentence, max_len = max_length)\n","    elif model == 'gpt2_tuned' and training_set == \"T&C\":\n","      raw_output = gen_story(my_model=gpt2_tuned, seed=seed_sentence, max_len = max_length)\n","    elif model == 'gpt2_tuned_unfrozen' and training_set == \"T&C\":\n","      raw_output = gen_story(my_model=gpt2_tuned_unfrozen, seed=seed_sentence, max_len = max_length)\n","    elif model == 'gpt2_simple' and training_set == \"T&C\":\n","      raw_output = gen_story_gpt2_simple(seed=seed_sentence, max_len = max_length)\n","    else:\n","        print(\"Invalid model/training-set combination.\")\n","        raw_output = \"\"\n","    \n","    end_time = time.time()\n","    elapsed_time = end_time - start_time\n","\n","    return post_proc(raw_output), elapsed_time"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ClVBYKLLPa7K"},"source":["### Evaluation Grid Generator"]},{"cell_type":"code","metadata":{"id":"ybOdXi17Pa7L"},"source":["Seed_sentences = [\n","    \"random\",\n","    \"constructed\"\n","]\n","\n","Models = [\n","    'ngram_4',\n","    'ngram_6', \n","    'gpt2',\n","    'gpt2_tuned',\n","    'gpt2_tuned_unfrozen',\n","    'gpt2_simple'\n","]\n","\n","Training_sets = [\"T&C\"]\n","\n","Max_lengths = [100]\n","\n","Stories_per_permutation = 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UDdWQq0PX-_3"},"source":["Stories = pd.DataFrame(columns=['Model',\n","                    'Training_set',\n","                    'Seed_sentence',\n","                    'Max_length',\n","                    'Number',\n","                    'Story',\n","                    'Execution_time'])\n","Permutation_loop_progress = \"All required stories composed for Model:\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_5KLi9RQPa7M"},"source":["for Model in Models:\n","  for Training_set in Training_sets:\n","    for Seed_sentence in Seed_sentences:\n","      for Max_length in Max_lengths:\n","        for Story_number in range(1,Stories_per_permutation+1):\n","          print(\"Composing (using model = \", Model, \", training_set = \",Training_set, \", seed_sentence = \", Seed_sentence, \", and max_length = \",Max_length,\") story \", Story_number, sep=\"\")\n","          story, execution_time = compose_story(model=Model, training_set=Training_set, seed_sentence=Seed_sentence, max_length=Max_length)\n","          if story != \"\":\n","              entry = {\n","                  'Model' : Model,\n","                  'Training_set': Training_set,\n","                  'Seed_sentence' : Seed_sentence,\n","                  'Max_length' : Max_length,\n","                  'Number': Story_number,\n","                  'Story' : story,\n","                  'Execution_time': execution_time\n","              }\n","              Stories = Stories.append(entry, True)\n","  \n","  Permutation_loop_progress = Permutation_loop_progress + \"\\n    \" + Model\n","  print(Permutation_loop_progress)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cYzJsxyKPa7M"},"source":["Stories"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jyeihnt1Pa7M"},"source":["Stories = Stories.sample(frac=1).reset_index(drop=True)\n","Stories"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2tiekNJGPa7N"},"source":["Stories.to_csv(data_path + \"evaluation/\" + \"RawEvaluationGrid.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oI3yo6BFPa7N"},"source":["## Manual Rating\n","\n","Incomplete"]},{"cell_type":"markdown","metadata":{"id":"3dc5yumBPa7N"},"source":["Functions"]},{"cell_type":"code","metadata":{"id":"I0N_qFPBPa7N"},"source":["def rating(prompt, min_rating, max_rating):\n","    answer = input(prompt)\n","    answer = int(answer)\n","    return answer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2BbMwdAFPa7O"},"source":["def rating_loop(EvaluationGrid, rater_name):\n","    H_line = \"---------------------------------------------------------------------------\"\n","    Header = (H_line + \"\\n\" + \"Manual evaluation in progress.\\nRater: \" + rater_name + \"\\n\" + H_line)\n","    max_ind = len(EvaluationGrid)\n","    \n","    for ind in EvaluationGrid.index:\n","        while True:\n","            clear_output()\n","            print(Header)\n","            print(\"Story number %d of %d to be evaluated.\\nStory:\"%(ind+1, max_ind))\n","            print(EvaluationGrid.loc[ind, 'Story'])\n","\n","            creativity = rating('Creativity: ', 1, 5)\n","            correctness = rating('Correctness: ', 1, 5)\n","            child_friendliness = rating('Child-friendliness: ', 1, 5)\n","\n","            satisfied = input(\"Are you satisfied with these ratings (type 'y' if yes)?\")\n","            if satisfied == 'y':\n","                EvaluationGrid.loc[ind, 'creativity'] = creativity\n","                EvaluationGrid.loc[ind, 'correctness'] = correctness\n","                EvaluationGrid.loc[ind, 'child_friendliness'] = child_friendliness\n","                break"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HeQcKLqQ39a6"},"source":["## Rating Analysis\n","Incomplete"]}]}
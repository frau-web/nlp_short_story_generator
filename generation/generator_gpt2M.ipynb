{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"generator_gpt2M.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"YFCOifqip0xk"},"source":["# Generator File: GPT2-Medium"]},{"cell_type":"markdown","metadata":{"id":"JGv_hMXuqCMv"},"source":["## 1. Importing libraries and functions"]},{"cell_type":"code","metadata":{"id":"0jNg-wTt2-zV"},"source":["try:\n","    print(gpt2_libraries_progress)\n","except NameError:\n","    %run ./generation/generator_gpt2_libraries.ipynb"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Na340M7NqFId"},"source":["## 2. Importing model"]},{"cell_type":"code","metadata":{"id":"vqlxbW3cuumM"},"source":["print(\"Loading model...\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KHhdXASkYD_u"},"source":["# Define tokenizer\n","gpt2m_tokenizer = GPT2TokenizerFast.from_pretrained('gpt2-medium', add_prefix_space=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SvNyBv6yp_T3"},"source":["# Import GPT2 pretrained model\n","from transformers import GPT2LMHeadModel\n","gpt2m = GPT2LMHeadModel.from_pretrained('gpt2-medium')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KVfp-qYcWQAa"},"source":["##3. Loading functions"]},{"cell_type":"code","metadata":{"id":"dwQqACPmW44J"},"source":["def gen_story_gpt2m(seed, max_len):\n","  return gen_story(my_model = gpt2m, my_tokenizer = gpt2m_tokenizer, seed=seed, max_len=max_len) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t7f334Vu4Hpp"},"source":["clear_output()\n","print(\"Function and Model now available for use:\")\n","print(\"    gen_story_gpt2m(seed, max_len)\")\n","print(\"    *Based on GPT2-Medium | Untuned\")"],"execution_count":null,"outputs":[]}]}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "generator_gpt2_tuned.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFCOifqip0xk"
      },
      "source": [
        "# Generator File: GPT2-Medium Finetuned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGv_hMXuqCMv"
      },
      "source": [
        "## 1. Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOfVzQL1pM_8",
        "outputId": "2fb3a987-4dbb-4541-b7ae-8455557f53c8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMZutYylp8ns",
        "outputId": "31f37b2d-ce00-42c3-c789-6969f37bc5a4"
      },
      "source": [
        "# Install required libraries\n",
        "\n",
        "!pip install tokenizers\n",
        "!pip install transformers \n",
        "\n",
        "!pip install fastai==2.0.15\n",
        "!pip install fastai2==0.0.30\n",
        "!pip install fastcore==1.0.16\n",
        "\n",
        "!pip install -Uqq fastbook\n",
        "\n",
        "#!pip install torch==1.6.0 torchvision==0.7.0 "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.7/dist-packages (0.10.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Collecting fastai==2.0.15\n",
            "  Using cached https://files.pythonhosted.org/packages/98/2e/d4dcc69f67b4557c8543a4c65d3e136b1929b01136b227ceb986e2596825/fastai-2.0.15-py3-none-any.whl\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fastai==2.0.15) (1.1.5)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from fastai==2.0.15) (1.8.1+cu101)\n",
            "Requirement already satisfied: torchvision>=0.7 in /usr/local/lib/python3.7/dist-packages (from fastai==2.0.15) (0.9.1+cu101)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastai==2.0.15) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fastai==2.0.15) (2.23.0)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai==2.0.15) (1.0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from fastai==2.0.15) (0.22.2.post1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai==2.0.15) (3.13)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from fastai==2.0.15) (1.4.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from fastai==2.0.15) (7.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai==2.0.15) (3.2.2)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (from fastai==2.0.15) (2.2.4)\n",
            "Requirement already satisfied: fastcore>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from fastai==2.0.15) (1.3.20)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastai==2.0.15) (19.3.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai==2.0.15) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai==2.0.15) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai==2.0.15) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->fastai==2.0.15) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->fastai==2.0.15) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==2.0.15) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==2.0.15) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==2.0.15) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==2.0.15) (3.0.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fastai==2.0.15) (1.0.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai==2.0.15) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai==2.0.15) (0.10.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai==2.0.15) (2.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai==2.0.15) (4.41.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy->fastai==2.0.15) (56.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai==2.0.15) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai==2.0.15) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai==2.0.15) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai==2.0.15) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai==2.0.15) (3.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai==2.0.15) (0.8.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai==2.0.15) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai==2.0.15) (1.0.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->fastai==2.0.15) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->fastai==2.0.15) (3.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->fastai==2.0.15) (3.4.1)\n",
            "\u001b[31mERROR: fastbook 0.0.16 has requirement fastai>=2.1, but you'll have fastai 2.0.15 which is incompatible.\u001b[0m\n",
            "Installing collected packages: fastai\n",
            "  Found existing installation: fastai 2.3.1\n",
            "    Uninstalling fastai-2.3.1:\n",
            "      Successfully uninstalled fastai-2.3.1\n",
            "Successfully installed fastai-2.0.15\n",
            "Requirement already satisfied: fastai2==0.0.30 in /usr/local/lib/python3.7/dist-packages (0.0.30)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (20.9)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (1.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (0.22.2.post1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (1.1.5)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (2.2.4)\n",
            "Requirement already satisfied: fastcore>=0.1.34 in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (1.3.20)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (19.3.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (7.1.2)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (1.8.1+cu101)\n",
            "Requirement already satisfied: torchvision>=0.7 in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (0.9.1+cu101)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (3.2.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (3.13)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->fastai2==0.0.30) (2.4.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fastprogress>=0.2.4->fastai2==0.0.30) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fastai2==0.0.30) (1.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fastai2==0.0.30) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastai2==0.0.30) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastai2==0.0.30) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastai2==0.0.30) (2.10)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai2==0.0.30) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai2==0.0.30) (2.8.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai2==0.0.30) (3.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai2==0.0.30) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai2==0.0.30) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai2==0.0.30) (2.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai2==0.0.30) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai2==0.0.30) (4.41.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai2==0.0.30) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai2==0.0.30) (0.8.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai2==0.0.30) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai2==0.0.30) (7.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy->fastai2==0.0.30) (56.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->fastai2==0.0.30) (3.7.4.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai2==0.0.30) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai2==0.0.30) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->fastai2==0.0.30) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->fastai2==0.0.30) (3.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->fastai2==0.0.30) (3.4.1)\n",
            "Collecting fastcore==1.0.16\n",
            "  Using cached https://files.pythonhosted.org/packages/99/c9/bd299caa1f1c002495bc9ffb98d31605e78a131a2ba3ba66a2682a7ab245/fastcore-1.0.16-py3-none-any.whl\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastcore==1.0.16) (19.3.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastcore==1.0.16) (20.9)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->fastcore==1.0.16) (2.4.7)\n",
            "\u001b[31mERROR: nbdev 1.1.14 has requirement fastcore>=1.3.19, but you'll have fastcore 1.0.16 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastrelease 0.1.11 has requirement fastcore>=1.3.13, but you'll have fastcore 1.0.16 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastbook 0.0.16 has requirement fastai>=2.1, but you'll have fastai 2.0.15 which is incompatible.\u001b[0m\n",
            "Installing collected packages: fastcore\n",
            "  Found existing installation: fastcore 1.3.20\n",
            "    Uninstalling fastcore-1.3.20:\n",
            "      Successfully uninstalled fastcore-1.3.20\n",
            "Successfully installed fastcore-1.0.16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLvHmuwEp9l0"
      },
      "source": [
        "# Importing required libraries\n",
        "import pandas as pd\n",
        "\n",
        "from fastai.text.all import *\n",
        "\n",
        "import fastbook\n",
        "from fastbook import *\n",
        "fastbook.setup_book()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Na340M7NqFId"
      },
      "source": [
        "## 2. Importing model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvNyBv6yp_T3"
      },
      "source": [
        "# Import GPT2 tokenizer\n",
        "from transformers import GPT2TokenizerFast\n",
        "\n",
        "# Load pre-trained model (weights)\n",
        "pretrained_weights = 'gpt2-medium'\n",
        "\n",
        "# Define tokenizer and model\n",
        "tokenizer = GPT2TokenizerFast.from_pretrained(pretrained_weights, add_prefix_space=True)    # for documentation: https://huggingface.co/transformers/_modules/transformers/tokenization_gpt2.html"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_wcUTlOpt0s"
      },
      "source": [
        "# To process this data to train a model, we need to build a Transform that will be applied lazily.\n",
        "\n",
        "class TransformersTokenizer(Transform):\n",
        "    def __init__(self, tokenizer): self.tokenizer = tokenizer\n",
        "    def encodes(self, x): \n",
        "        toks = self.tokenizer.tokenize(x)\n",
        "        return tensor(self.tokenizer.convert_tokens_to_ids(toks))\n",
        "    def decodes(self, x): return TitledStr(self.tokenizer.decode(x.cpu().numpy()))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0EfwfHWpuoX"
      },
      "source": [
        "# We use callbacks in case we want to alter the behavior of the training loop \n",
        "class DropOutput(Callback):\n",
        "    def after_pred(self): self.learn.pred = self.pred[0]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbZOHpoCpyq7"
      },
      "source": [
        "# Load model\n",
        "model_path = \"/content/gdrive/MyDrive/NLP/model/gpt2-finedtuned.pkl\"\n",
        "\n",
        "gpt2_tuned = load_learner(model_path)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xn1b1uHqHhr"
      },
      "source": [
        "## 3. Generating Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eEr2WRmqJUF"
      },
      "source": [
        "# Generate Output\n",
        "\n",
        "TEMP = 0.6     # Temperature is used to control the randomness of predictions by scaling the logits before applying softmax (small (0.2): model is more confident but also more conservative, large( 1.0): more diversity but also more mistakes)\n",
        "TOP_K = 40\n",
        "TOP_P = 0.85\n",
        "NUM_SEQ = 1\n",
        "\n",
        "def gen_story(my_model, seed, max_len):\n",
        "\n",
        "  # take input\n",
        "  prompt_ids = tokenizer.encode(seed)\n",
        "  inp = tensor(prompt_ids)[None]#.cuda() # un-do .cuda() if no GPU available\n",
        " \n",
        "  # generate output\n",
        "  sample_outputs = my_model.generate(\n",
        "                              inp,\n",
        "                              do_sample = True, \n",
        "                              max_length = max_len,     \n",
        "                              temperature = TEMP,\n",
        "                              top_k = TOP_K, \n",
        "                              top_p = TOP_P, \n",
        "                              num_return_sequences = NUM_SEQ,\n",
        "\n",
        "  )\n",
        "\n",
        "  # Print Output\n",
        "  for i, sample_output in enumerate(sample_outputs):\n",
        "    print(\"{}: {}...\".format(i, tokenizer.decode(sample_output, skip_special_tokens = True)))\n",
        "    return"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCQMZeicqN7z"
      },
      "source": [
        "# Run if using GPU and if RuntimeError: Input, output and indices must be on the current device \n",
        "#device = \"cuda:0\"\n",
        "#gpt2 = gpt2.to(device)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nr8VcH25q2DL"
      },
      "source": [
        "# Provided by evaluation/story-generator application\n",
        "#seed = \"Our story begins with an king that lived in his castle with his queen and their two children and they ruled over a large kingdom of happy people.\"\n",
        "#max_len = 350"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXUwmrecqibO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5325f3f-3129-4ef7-95db-ea26f05ef95b"
      },
      "source": [
        "# Generate output\n",
        "#my_model = gpt2_tuned                   # insert model for text generation\n",
        "\n",
        "#gen_story(my_model,seed,max_len)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0:  Our story begins with an king that lived in his castle with his queen and their two children and they ruled over a large kingdom of happy people.    'Oh, Mother, Mother, Mother, Mother, Mother, Mother, Mother,                                                                                                                                                                                                                                                                                                             ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kae3-w_krsaC"
      },
      "source": [
        "### Generate other fine-tuned models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4ZDsDG8tB11"
      },
      "source": [
        "# Split a GPT2 model in 4 groups for differential learning rates (Code from Finetuning English GPT2 to any language)\n",
        "\n",
        "def splitter(model):\n",
        "    \"Split a GPT2 `model` in 3 groups for differential learning rates.\"\n",
        "    \n",
        "    # First layers group : decoder blocks from 0 to 3\n",
        "    modules = []\n",
        "    for i in range(4): modules.append(model.transformer.h[i])\n",
        "    groups = [nn.Sequential(*modules)]\n",
        "\n",
        "    # Second layers group : decoder blocks from 4 to 7\n",
        "    modules = []\n",
        "    for i in range(4,8,1): modules.append(model.transformer.h[i])\n",
        "    groups = L(groups + [nn.Sequential(*modules)])\n",
        "\n",
        "    # Third layers group : decoder blocks from 8 to 11\n",
        "    modules = []\n",
        "    for i in range(8,12,1): modules.append(model.transformer.h[i])\n",
        "    groups = L(groups + [nn.Sequential(*modules)])\n",
        "    \n",
        "    # Fourth layers group : embeddings matrices wte and wpe + LayerNorm at the model output\n",
        "    groups = L(groups + [nn.Sequential(model.transformer.wte,model.transformer.wpe,model.transformer.ln_f)])\n",
        "    \n",
        "    return groups.map(params)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EWqgW7XsGyz",
        "outputId": "b758fe77-ef2b-4b60-b45d-adf43316edfc"
      },
      "source": [
        "# Load model\n",
        "model_path = \"/content/gdrive/MyDrive/NLP/model/gpt2_3epoch_lr25e-3.pkl\"\n",
        "\n",
        "gpt2_3epoch_lr25e_3 = load_learner(model_path)\n",
        "\n",
        "my_model = gpt2_3epoch_lr25e_3                  # insert model for text generation\n",
        "\n",
        "gen_story(my_model,seed,max_len)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0:  Our story begins with an king that lived in his castle with his queen and their two children and they ruled over a large kingdom of happy people.    He did not know that he was by himself.   The mother duck was very angry at this, but she thought that she would be glad to have some eggs.                                                                                                                                                                                                                                                                                            ...\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
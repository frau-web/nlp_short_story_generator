{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"generator_gpt2M_tuned_on_toddler.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"YFCOifqip0xk"},"source":["# Generator File: GPT2-Medium Finetuned"]},{"cell_type":"markdown","metadata":{"id":"JGv_hMXuqCMv"},"source":["## 1. Importing libraries and functions"]},{"cell_type":"code","metadata":{"id":"TFDH8XPeAPL4"},"source":["try:\n","    print(gpt2_libraries_progress)\n","except NameError:\n","    %run ./generation/generator_gpt2_libraries.ipynb"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Na340M7NqFId"},"source":["## 2. Importing model"]},{"cell_type":"code","metadata":{"id":"bGRUrrWButmw"},"source":["print(\"Loading model...\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tvrvbxEMas3a"},"source":["# Define tokenizer\n","gpt2m_tokenizer = GPT2TokenizerFast.from_pretrained('gpt2-medium', add_prefix_space=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HbZOHpoCpyq7"},"source":["# Load model\n","gpt2M_tuned_on_toddler = load_learner(model_path + \"gpt2M_tuned_on_toddler.pkl\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KVfp-qYcWQAa"},"source":["## 3. Loading functions"]},{"cell_type":"code","metadata":{"id":"dwQqACPmW44J"},"source":["def gen_story_gpt2m_tunedonT(seed, max_len):\n","  return gen_story(my_model = gpt2M_tuned_on_toddler, my_tokenizer = gpt2m_tokenizer, seed=seed, max_len=max_len) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t7f334Vu4Hpp"},"source":["clear_output()\n","print(\"Function and Model now available for use:\")\n","print(\"    gen_story_gpt2m_tunedonT(seed, max_len)\")\n","print(\"    *Based on GPT2-Medium | Tuned on input_stories_toddler.txt\")"],"execution_count":null,"outputs":[]}]}
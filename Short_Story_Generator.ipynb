{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"Short_Story_Generator.ipynb","provenance":[{"file_id":"https://github.com/frau-web/nlp_short_story_generator/blob/main/evaluation/Evaluation%20Pipelines.ipynb","timestamp":1620571305065}],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"zJ_LlOnpPa69"},"source":["# Short Story Generator"]},{"cell_type":"markdown","metadata":{"id":"AKlx-BPStzRc"},"source":["This is a top-level (i.e. it can be executed by the user) notebook that makes use of (calls) many other notebooks and files. The files (data) is shared using Google Drive and the other notebooks using GitHub. To connect to these external sources, it is thus imperrative that Steps 0 to 7 (contained under the **Load libraries & connect to code and data** heading) are followed first.\n","\n","If the user wants to investigate the code (annotated notebooks) called by this notebook, they can also be opened in Google Colab:\n","\n","File > Open notebook > GitHub > https://github.com/frau-web/nlp_short_story_generator.git\n","\n","---\n","\n","This specific notebook (in the section titled **Model Selection**) collects all trained Story Generating Models and loads one of them.\n","\n","\n","For an analysis that supports this choice, please see the Notebooks and Data in the \"evaluation\" folders of both the GitHub repository and the shared Google Drive folder.\n","\n","---\n","\n","Lastly (in the **Story Generator MVP** section), the selected model is used to create stories based on user input.\n"]},{"cell_type":"markdown","metadata":{"id":"bva_JtgCPeXY"},"source":["## Load libraries & connect to code and data\n","\n"]},{"cell_type":"markdown","metadata":{"id":"l7ejCVq0rKwB"},"source":["**Step 0:** Please run the following cell to load the required libraries and then follow Steps 1-5 and 6-7 to connect with and download, respectively, the data and additional code this notebook requires to function."]},{"cell_type":"code","metadata":{"id":"ZDVhH-RUriDt"},"source":["from IPython.display import clear_output\n","from google.colab import drive\n","import pandas as pd\n","import time"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HU51triAP0AY"},"source":["### Data from Google Drive"]},{"cell_type":"markdown","metadata":{"id":"VuyxnILUcF8U"},"source":["**Step 1:** Please navigate to the shared folder on Google Drive, named \"data\" that contains the project's data and select \"Add a shortcut to Drive\" to add a shortcut of the folder to YOUR Google Drive."]},{"cell_type":"markdown","metadata":{"id":"TkrIIJpOfP3x"},"source":["**Step 2:** Please mount YOUR Google Drive:"]},{"cell_type":"code","metadata":{"id":"0miRy0_7P3VK"},"source":["drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wuxmxv4wfWli"},"source":["**Step 3:** By using the \"Files\" tab in the Left-hand Sidebar of Colab, please navigate to the \"data\" (shortcut) folder that you created in Step 1 and, from the menu that appears when you click on the three dots next to \"data\", select \"Copy path\"."]},{"cell_type":"markdown","metadata":{"id":"7dRKzMLBgvm4"},"source":["**Step 4:** Please run the following cell and paste that path when prompted:"]},{"cell_type":"code","metadata":{"id":"K86y66ZSQB71"},"source":["data_path = input(\"Please paste the path to the 'data' folder as copied from the Colab files tab.\") + \"/\"\n","clear_output()\n","data_path"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o-r65X10g7Cd"},"source":["**Step 5:** Lastly, please test the connection using the following cell. If the output does not at least show ``` evaluation/ models/  stories/```\n","then the connection was not made correctly and the steps should be followed again.\n"]},{"cell_type":"code","metadata":{"id":"hExza-m1hTXS"},"source":["%cd $data_path\n","clear_output()\n","%ls"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JDNBoZKRPqSZ"},"source":["### Code from GitHub"]},{"cell_type":"markdown","metadata":{"id":"S0QH8S19nNR8"},"source":["**Step 6:** Please clone the GitHub repository by executing the cell below:"]},{"cell_type":"code","metadata":{"id":"EqGxx6j-llIL"},"source":["github_path = \"/content/github\"\n","%mkdir $github_path\n","%cd $github_path\n","! git clone https://github.com/frau-web/nlp_short_story_generator.git\n","code_path = \"/content/github/nlp_short_story_generator\"\n","%cd $code_path"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WGo4zoaBoL2w"},"source":["**Step 7:** Lastly, please confirm the propper execution of Step 6 by using the following cell. \n","\n","If the output does not at least show ```data/  evaluation/  generation/  ReadME.md  ``` then Step 6 was not executed correctly."]},{"cell_type":"code","metadata":{"id":"WaFM0vS3oT27"},"source":["%ls"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NQJU5vJu1Le4"},"source":["## Model Selection"]},{"cell_type":"markdown","metadata":{"id":"ptEVJboqTnnm"},"source":["In this section, each cell loads, defines and selects a model. **Only one of them should be executed.** (In other words, the last one executed will be used by the **Story Generator MVP** section.)"]},{"cell_type":"markdown","metadata":{"id":"ISV0Qpx0Pa7H"},"source":["### Preferred Model"]},{"cell_type":"code","metadata":{"id":"3hBCQOuG7sGD"},"source":["#GPT2-Small Model tuned on input_stories_toddlerpluschildren.txt using gpt2_simple library\n","#if this is not the first model cell executed, it might not execute at all.\n","%run ./generation/generator_gpt2Simple_tuned_on_tandc.ipynb\n","def selected_model(seed_sentence, max_length):\n","  return gen_story_gpt2_simple_tunedonTC(seed=seed_sentence, max_len = max_length)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t9xbSOGnPa7H"},"source":["### Other Models"]},{"cell_type":"code","metadata":{"id":"P5Qhn6Rt-a7w"},"source":["#N-gram model (6-gram) trained on input_stories_toddlerpluschildren.txt\n","training_stories_filename = \"input_stories_toddlerpluschildren.txt\"\n","%run ./generation/generator_ngram_6.ipynb\n","def selected_model(seed_sentence, max_length):\n","  return generate_text6(seed=seed_sentence, numwords=max_length)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CgBwDeSLEVNp"},"source":["#N-gram model (4-gram) trained on input_stories_toddlerpluschildren.txt\n","training_stories_filename = \"input_stories_toddlerpluschildren.txt\"\n","%run ./generation/generator_ngram_4.ipynb\n","def selected_model(seed_sentence, max_length):\n","  return generate_text4(seed=seed_sentence, numwords=max_length)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sNd7myV-Pa7I"},"source":["#Untuned GPT2-Medium Model\n","%run ./generation/generator_gpt2M.ipynb\n","def selected_model(seed_sentence, max_length):\n","  return gen_story_gpt2m(seed=seed_sentence, max_len = max_length)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QbRX07NXBxU8"},"source":["#GPT2-Medium Model tuned on input_stories_toddler.txt\n","%run ./generation/generator_gpt2M_tuned_on_toddler.ipynb\n","def selected_model(seed_sentence, max_length):\n","  return gen_story_gpt2m_tunedonT(seed=seed_sentence, max_len = max_length)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W_-baomzt9Je"},"source":["#GPT2-Medium Model tuned on input_stories_toddler.txt (Unfrozen)\n","%run ./generation/generator_gpt2M_tuned_on_toddler_unfrozen.ipynb\n","def selected_model(seed_sentence, max_length):\n","  return gen_story_gpt2m_tunedonT_unfrozen(seed=seed_sentence, max_len = max_length)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UITAGwVqeFCQ"},"source":["#GPT2-Small Model tuned on input_stories_toddlerpluschildren.txt\n","%run ./generation/generator_gpt2S_tuned_on_tandc.ipynb\n","def selected_model(seed_sentence, max_length):\n","  return gen_story_gpt2s_tunedonTC(seed=seed_sentence, max_len = max_length)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wGcuspKKd5g9"},"source":["#GPT2-Small Model tuned on input_stories_toddlerpluschildren.txt (Unfrozen)\n","%run ./generation/generator_gpt2S_tuned_on_tandc_unfrozen.ipynb\n","def selected_model(seed_sentence, max_length):\n","  return gen_story_gpt2s_tunedonTC_unfrozen(seed=seed_sentence, max_len = max_length)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hkXvORV7uzW4"},"source":["## Story Generator MVP"]},{"cell_type":"markdown","metadata":{"id":"aNQZZAMfu3hg"},"source":["All the cells in this section must be executed, but only after all the steps in the **Load libraries & connect to code and data** section have been completed, and after only one cell in the **Model Selection** section has been run."]},{"cell_type":"markdown","metadata":{"id":"kO8ExqHDPa7I"},"source":["### Definitions"]},{"cell_type":"code","metadata":{"id":"BIwVUKNMPa7J"},"source":["def post_proc(raw_story):\n","  if raw_story == \"\":\n","    proc_story = \"### STORY COULD NOT BE GENERATED ###\"\n","  else:\n","    proc_story = raw_story\n","\n","    proc_story = (raw_story\n","        .replace(\"\\\\' \", \" \")\n","        .replace(\" \\\\'\", \" \")\n","        .replace(\" '\", \" \")\n","        .replace(\"' \", \" \")\n","        .replace('\"', \"\")\n","        .replace('\\\\\"', \"\")\n","        .replace(\"  \", \" \")\n","        .replace(\". \", \". \\n \")\n","        .replace(\"  \", \" \")\n","        .strip()\n","        )\n","    proc_story = proc_story[:(proc_story.rfind(\"\\n\"))]\n","    \n","  return proc_story"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fKm7CJ0pvkQr"},"source":["def compose_story(seed_sentence, max_length = 250):\n","  return post_proc(selected_model(seed_sentence, max_length))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"smloZ2EAPa7H"},"source":["H_line = \"---------------------------------------------------------------------------\"\n","seed0 = \"Once upon a time\"\n","seed1 = \"Anthea and Robert were in London.\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V2xhRxVXPa7J"},"source":["### Model Prediction Pipeline"]},{"cell_type":"code","metadata":{"id":"Aoeg1Su8wpV-"},"source":["while True:\n","    clear_output()\n","    print(H_line)\n","    print(\"Welcome to the Short Story Generator.\\n Please choose a seed sentence, either by typing it out yourself, or by typing one of the options below:\")\n","    print(\"    '0': \" + seed0)\n","    print(\"    '1': \" + seed1)\n","    print(\"    'q' to Quit\")\n","\n","    answer = input(\"Option or Seed Sentence: \")\n","\n","    if answer == \"q\":\n","      break\n","    elif answer == \"0\":\n","      seed_sentence = seed0\n","    elif answer == \"1\":\n","      seed_sentence = seed1\n","    else:\n","      seed_sentence = answer\n","    \n","    print(\"Composing story...\")\n","    story = compose_story(seed_sentence)\n","    clear_output()\n","    print(H_line)\n","    print(story)\n","    print(H_line)\n","\n","    answer = input(\"Another story ('y' for yes)?\")\n","    if answer != \"y\":\n","      break"],"execution_count":null,"outputs":[]}]}
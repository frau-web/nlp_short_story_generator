{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Short_Story_Generator_v3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zw6w68Pom7Vs"
      },
      "source": [
        "# Short-Story Generator_v2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iP03-0UDxZVA"
      },
      "source": [
        "[WIP]\n",
        "Strategy: using a pre-trained model and fine-tuning it with our scenario-specific dataset. \n",
        "Why: pre-trained model has already trained the vocab and position embedding matrix for general English language (the model already learned the grammar, sentence structure, language rules....), we do not need to retrain this (would be computationally expensive), additionally we can keep the model weights learned of this model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4Zo2rXXnEnO"
      },
      "source": [
        "## 1. Loading all libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qipOIbU3ryEP",
        "outputId": "075e76ef-d38e-4444-91e0-f05f1b1b5de5"
      },
      "source": [
        "# Install required libraries\n",
        "\n",
        "!pip install torch==1.6.0 torchvision==0.7.0 #downgrading to Pytorch 1.6 to prevent error, https://forums.fast.ai/t/attributeerror-fakeloader-object-has-no-attribute-persistent-workers/81167/5\n",
        "\n",
        "!pip install fastai==2.0.15\n",
        "!pip install fastai2==0.0.30\n",
        "!pip install fastcore==1.0.16\n",
        "\n",
        "!pip install -Uqq fastbook\n",
        "\n",
        "!pip install tokenizers\n",
        "!pip install transformers #!pip install -Uq transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==1.6.0\n",
            "  Using cached https://files.pythonhosted.org/packages/5d/5e/35140615fc1f925023f489e71086a9ecc188053d263d3594237281284d82/torch-1.6.0-cp37-cp37m-manylinux1_x86_64.whl\n",
            "Collecting torchvision==0.7.0\n",
            "  Using cached https://files.pythonhosted.org/packages/4d/b5/60d5eb61f1880707a5749fea43e0ec76f27dfe69391cdec953ab5da5e676/torchvision-0.7.0-cp37-cp37m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.7.0) (7.1.2)\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.6.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastai 2.3.0 has requirement torch<1.8,>=1.7.0, but you'll have torch 1.6.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastai 2.3.0 has requirement torchvision<0.9,>=0.8, but you'll have torchvision 0.7.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.7.1\n",
            "    Uninstalling torch-1.7.1:\n",
            "      Successfully uninstalled torch-1.7.1\n",
            "  Found existing installation: torchvision 0.8.2\n",
            "    Uninstalling torchvision-0.8.2:\n",
            "      Successfully uninstalled torchvision-0.8.2\n",
            "Successfully installed torch-1.6.0 torchvision-0.7.0\n",
            "Collecting fastai==2.0.15\n",
            "  Using cached https://files.pythonhosted.org/packages/98/2e/d4dcc69f67b4557c8543a4c65d3e136b1929b01136b227ceb986e2596825/fastai-2.0.15-py3-none-any.whl\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastai==2.0.15) (19.3.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai==2.0.15) (3.13)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fastai==2.0.15) (1.1.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from fastai==2.0.15) (1.4.1)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai==2.0.15) (1.0.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai==2.0.15) (3.2.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from fastai==2.0.15) (7.1.2)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from fastai==2.0.15) (1.6.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from fastai==2.0.15) (0.22.2.post1)\n",
            "Requirement already satisfied: torchvision>=0.7 in /usr/local/lib/python3.7/dist-packages (from fastai==2.0.15) (0.7.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (from fastai==2.0.15) (2.2.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastai==2.0.15) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fastai==2.0.15) (2.23.0)\n",
            "Requirement already satisfied: fastcore>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from fastai==2.0.15) (1.3.19)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai==2.0.15) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai==2.0.15) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai==2.0.15) (1.19.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai==2.0.15) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai==2.0.15) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai==2.0.15) (0.10.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->fastai==2.0.15) (0.16.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fastai==2.0.15) (1.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy->fastai==2.0.15) (56.0.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai==2.0.15) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai==2.0.15) (4.41.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai==2.0.15) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai==2.0.15) (3.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai==2.0.15) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai==2.0.15) (0.8.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai==2.0.15) (2.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai==2.0.15) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai==2.0.15) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai==2.0.15) (0.4.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==2.0.15) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==2.0.15) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==2.0.15) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==2.0.15) (2.10)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->fastai==2.0.15) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->fastai==2.0.15) (3.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->fastai==2.0.15) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->fastai==2.0.15) (3.7.4.3)\n",
            "\u001b[31mERROR: fastbook 0.0.16 has requirement fastai>=2.1, but you'll have fastai 2.0.15 which is incompatible.\u001b[0m\n",
            "Installing collected packages: fastai\n",
            "  Found existing installation: fastai 2.3.0\n",
            "    Uninstalling fastai-2.3.0:\n",
            "      Successfully uninstalled fastai-2.3.0\n",
            "Successfully installed fastai-2.0.15\n",
            "Requirement already satisfied: fastai2==0.0.30 in /usr/local/lib/python3.7/dist-packages (0.0.30)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (20.9)\n",
            "Requirement already satisfied: torchvision>=0.7 in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (0.7.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (1.1.5)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (1.0.0)\n",
            "Requirement already satisfied: fastcore>=0.1.34 in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (1.3.19)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (3.13)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (2.2.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (0.22.2.post1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (1.6.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (7.1.2)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (19.3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->fastai2==0.0.30) (2.4.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.7->fastai2==0.0.30) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai2==0.0.30) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai2==0.0.30) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai2==0.0.30) (0.10.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai2==0.0.30) (2018.9)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai2==0.0.30) (0.8.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy->fastai2==0.0.30) (56.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai2==0.0.30) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai2==0.0.30) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai2==0.0.30) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai2==0.0.30) (1.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai2==0.0.30) (2.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai2==0.0.30) (3.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai2==0.0.30) (7.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai2==0.0.30) (1.1.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai2==0.0.30) (4.41.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fastai2==0.0.30) (1.0.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->fastai2==0.0.30) (0.16.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastai2==0.0.30) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fastai2==0.0.30) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastai2==0.0.30) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastai2==0.0.30) (1.24.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->fastai2==0.0.30) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->fastai2==0.0.30) (3.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->fastai2==0.0.30) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->fastai2==0.0.30) (3.4.1)\n",
            "Collecting fastcore==1.0.16\n",
            "  Using cached https://files.pythonhosted.org/packages/99/c9/bd299caa1f1c002495bc9ffb98d31605e78a131a2ba3ba66a2682a7ab245/fastcore-1.0.16-py3-none-any.whl\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastcore==1.0.16) (19.3.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastcore==1.0.16) (20.9)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->fastcore==1.0.16) (2.4.7)\n",
            "\u001b[31mERROR: nbdev 1.1.14 has requirement fastcore>=1.3.19, but you'll have fastcore 1.0.16 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastrelease 0.1.11 has requirement fastcore>=1.3.13, but you'll have fastcore 1.0.16 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastbook 0.0.16 has requirement fastai>=2.1, but you'll have fastai 2.0.15 which is incompatible.\u001b[0m\n",
            "Installing collected packages: fastcore\n",
            "  Found existing installation: fastcore 1.3.19\n",
            "    Uninstalling fastcore-1.3.19:\n",
            "      Successfully uninstalled fastcore-1.3.19\n",
            "Successfully installed fastcore-1.0.16\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.7.1 which is incompatible.\u001b[0m\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.7/dist-packages (0.10.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Po51UfQnDs8"
      },
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "\n",
        "from fastai.text.all import *\n",
        "\n",
        "import fastbook\n",
        "from fastbook import *\n",
        "fastbook.setup_book()\n",
        "\n",
        "from IPython.display import display,HTML"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6DhKQ-TnitZ"
      },
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2TokenizerFast"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0a0JiaMfANq"
      },
      "source": [
        "Let's load our English GPT-2 pretrained model. Given the size of the model and our requirements to produce simple, child-like language, we will load only the small GPT-2 model with 768MM parameters (vs. medium with 1024MM parameters and large with 1280MM parameters). The extra large model with 1600MM was never released due to potentially harmful uses. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02G06idfjjON"
      },
      "source": [
        "The full configuration of the GPT-2 small can be found here: https://huggingface.co/transformers/model_doc/gpt2.html#transformers.GPT2Config\n",
        "\n",
        "We load a specific class of the GPT2 model, the GPT2LMHeadModel: it is a GPT2 Model transformer with a language modeling head on top (linear layer with weights tied to the input embeddings). It inherits its configuration from pretrainedModel; this is also where we load the weights from."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gx9_ctBno00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6503cee3-3f47-47e7-cc03-1791f89f559c"
      },
      "source": [
        "# Load pre-trained model (weights)\n",
        "pretrained_weights = 'gpt2'\n",
        "\n",
        "tokenizer = GPT2TokenizerFast.from_pretrained(pretrained_weights)\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained(pretrained_weights)\n",
        "\n",
        "# Set the model in evaluation mode to deactivate the DropOut modules\n",
        "# This is IMPORTANT to have reproducible results during evaluation!\n",
        "model.eval()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSfFYYIRkSbQ"
      },
      "source": [
        "When using a pretrained model, it is important to use the associated pretrained tokenizer with it to ensure that it will split the text for the fine-tuning in the exact same way as the pretraining corpus and it will use the same correspondance token to index (vocab) as during pretraining. The GPT-2 tokenizer is based on Byte-Pair-Encodings. It detects the beinning of a word by the preceding space and has been trained to treat spaces like parts of the tokens (a bit like sentencepiece) so a word will be encoded differently whether it is at the beginning of the sentence (without space) or not. [Source](https://huggingface.co/transformers/model_doc/gpt2.html#transformers.GPT2Config)\n",
        "The English pre-trained GPT-2 tokenizer consists of a vocab of 50.257 tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQDvg2etkR72"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3qjWcKqnJg5"
      },
      "source": [
        "## 2. Loading Preprocessing Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2O9EDHECnMJe"
      },
      "source": [
        "# Import the data\n",
        "gist = \"https://gist.githubusercontent.com/frau-web/84b7a2155e97d479db0ca91b6fc3a0db/raw/89460c734dd7ba87ae6e6b4c4ffaebfa2f8f2f81/shortstories.txt\"\n",
        "df = pd.read_csv(gist, sep='\\t', header=None) \n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7TQTa1hqKQP"
      },
      "source": [
        "# Split into test and train\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_test_ratio = 0.9\n",
        "#train_valid_ratio = 7/9\n",
        "df_full_train, df_test = train_test_split(df, train_size = train_test_ratio, random_state = 1)\n",
        "#df_train, df_valid = train_test_split(df_full_train, train_size = train_valid_ratio, random_state = 1)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gAj0HvVp9Fk"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXFJXcLhV84p"
      },
      "source": [
        "\n",
        "We will now build a Transform that will be applied lazily, using the **fastAI Tokenizer**. In a  fastai transform we can define (among others): \n",
        "- an **encodes method**: applied when calling the transform (think: forward method in a neural net module)\n",
        "- a **decodes method**: applied when calling the decode method of the transform, e.g. if anything needs to be decoded for showing purposes (converting ids to a text)\n",
        "[Source](https://medium.com/@pierre_guillou/faster-than-training-from-scratch-fine-tuning-the-english-gpt-2-in-any-language-with-hugging-f2ec05c98787)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjfOEDE0n0fO"
      },
      "source": [
        "# To process this data to train a model, we need to build a Transform that will be applied lazily.\n",
        "\n",
        "class TransformersTokenizer(Transform):\n",
        "    def __init__(self, tokenizer): self.tokenizer = tokenizer\n",
        "    def encodes(self, x): \n",
        "        toks = self.tokenizer.tokenize(x)\n",
        "        return tensor(self.tokenizer.convert_tokens_to_ids(toks))\n",
        "    def decodes(self, x): return TitledStr(self.tokenizer.decode(x.cpu().numpy()))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQGboXNApZYM"
      },
      "source": [
        "\n",
        "\n",
        "Two comments on the code above:\n",
        "- in encodes we don't use the tokenizer.encode method since it does some additional preprocessing for the model after tokenizing and numericalizing (the part throwing a warning before). Here we don't need any post-processing so it's fine to skip it.\n",
        "- in decodes we return a TitledStr object and not just a plain string. That's a fastai class that adds a show method to the string, which will allow us to use all the fastai show methods.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxDGr33lXLkS"
      },
      "source": [
        "Next, we are **creating our Dataset and Dataloader** using Transform and a TfmdList. \n",
        "Tfmd List contains the training and validation dataset, which we create with 'splits'. \n",
        "Since we are dealing with a Language Model, we specify dl_type= LMDataLoader when converting the TfmdLists (containing our train and validation data) to DataLoaders. \n",
        "The Fastai library expects its input as a DataLoader object, containing train and validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KafNA1LvpVn-"
      },
      "source": [
        "# We gather all texts in one numpy array (since it will be easier to use this way with fastai)\n",
        "all_texts = np.concatenate([df_full_train[0].values, df_test[0].values])\n",
        "\n",
        "# We define the split between training and validation data\n",
        "splits = [range_of(df_full_train), list(range(len(df_full_train), len(all_texts)))]\n",
        "\n",
        "# We create the tls [WIP - EXPLAIN WHAT TLS IS]\n",
        "tls = TfmdLists(all_texts, TransformersTokenizer(tokenizer), splits=splits, dl_type=LMDataLoader)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnoGOTrqqvaA",
        "outputId": "cc690b4f-7849-4aea-da51-69b9c6fe99d1"
      },
      "source": [
        "tls.train[0],tls.valid[0]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1026,  373,  355, 4692,  379, 1363,  355,  287,  262, 4675,   13, 1119,  547, 1165, 3595,  284,  423]),\n",
              " tensor([  464,  6175,  2227,   284,   307,   588,   262, 11858,    13,  1406,   339,   531,   284, 31771,    11,   366,    40,   481]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8U14f9kq1jG",
        "outputId": "87320789-3c08-48f5-9982-6921d3c27854"
      },
      "source": [
        "show_at(tls.train, 0)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "It was as cold at home as in the street. They were too poor to have\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gnNVCKuq9vh"
      },
      "source": [
        "[tbd if rewrite]: The fastai library expects the data to be assembled in a DataLoaders object (something that has a training and validation dataloader). We can get one by using the dataloaders method. We just have to specify a batch size and a sequence length. We'll train with sequences of size 256 (GPT2 used sequence length 1024, but not everyone has enough GPU RAM for that):\n",
        "[Comment from Portuguese:]  \n",
        "- Let’s use a batch size of 8 (a value higher gives a “CUDA out of memory error” on our single GPU).\n",
        "- Since the GPT-2 model was trained with sequences of size 1024, we use this sequence length (it’s a stateless model, so it will change the perplexity if we use less)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fXhPuQBq_DO"
      },
      "source": [
        "bs,sl = 4,256\n",
        "dls = tls.dataloaders(bs=bs, seq_len=sl)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "X25EPI8zrEhW",
        "outputId": "4c5abfd3-ee9a-4ec5-a79a-f51fc55d3ca4"
      },
      "source": [
        "dls.show_batch(max_n=2)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>text_</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tool-shed, perhaps hidden underneath a flower-pot. He began to turnAll the gods came around to see. Then Loki came up to show his things.So Brok blew as hard as he could.happened, he came out, and climbed upon a wheelbarrow and peeped over.step--pit pat, paddle pat! pit pat, waddle pat!Nutkin began again \"Arthur O'Bower has broken his band, he comes roaring up the land!When Sif woke up and saw that her hair was gone, she cried andwill fly up to Thor's house and get the hammer.\"The wolf ran off and took a short way, but Red Riding-Hood stopped toOn the third day the squirrels got up very early and went fishing; theyWhen Red Riding-Hood tapped on the door, the wolf called out, \"Who isanimals.He lost one of his shoes among the cabbages, and the other shoeThey cut at the Harpies but could not hurt them.to Owl Island to gather nuts.Just then</td>\n",
              "      <td>-shed, perhaps hidden underneath a flower-pot. He began to turnAll the gods came around to see. Then Loki came up to show his things.So Brok blew as hard as he could.happened, he came out, and climbed upon a wheelbarrow and peeped over.step--pit pat, paddle pat! pit pat, waddle pat!Nutkin began again \"Arthur O'Bower has broken his band, he comes roaring up the land!When Sif woke up and saw that her hair was gone, she cried andwill fly up to Thor's house and get the hammer.\"The wolf ran off and took a short way, but Red Riding-Hood stopped toOn the third day the squirrels got up very early and went fishing; theyWhen Red Riding-Hood tapped on the door, the wolf called out, \"Who isanimals.He lost one of his shoes among the cabbages, and the other shoeThey cut at the Harpies but could not hurt them.to Owl Island to gather nuts.Just then</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>,Peter scuttered underneath the bushes. But presently, as nothingThen the same fly came in and bit him again.kill Jason.down like a little red cherry, singing \"Riddle me, riddle me, rot-tot-tote! He said to Brok, \"Now blow as hard as you can.\"How big your ears are, grandma.Her feet were bare. When she left home, she had on some big slippersThen Loki said, \"I can't stand this. I will get the apples for you.\"Then Sindre put a lump of iron into the fire.Peter gave himself up for lost, and shed big tears; but his sobs wereGretchen got colder and colder.a Christmas tree. Very many candles were on the tree. It was fulltied was not far off.duckling.There on the grass was a fine large sheep. This sheep had a fleece ofAnd Sindre went out. Brok blew and blew. The same mean fly came again,By and by he grew tame and let the children</td>\n",
              "      <td>Peter scuttered underneath the bushes. But presently, as nothingThen the same fly came in and bit him again.kill Jason.down like a little red cherry, singing \"Riddle me, riddle me, rot-tot-tote! He said to Brok, \"Now blow as hard as you can.\"How big your ears are, grandma.Her feet were bare. When she left home, she had on some big slippersThen Loki said, \"I can't stand this. I will get the apples for you.\"Then Sindre put a lump of iron into the fire.Peter gave himself up for lost, and shed big tears; but his sobs wereGretchen got colder and colder.a Christmas tree. Very many candles were on the tree. It was fulltied was not far off.duckling.There on the grass was a fine large sheep. This sheep had a fleece ofAnd Sindre went out. Brok blew and blew. The same mean fly came again,By and by he grew tame and let the children</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2san9ANrTKZ"
      },
      "source": [
        "### - Alternative\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ol-p4tNrX9_"
      },
      "source": [
        "Another way to gather the data is to preprocess the texts once and for all and only use the transform to decode the tensors to texts:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1jDD-_KrYjC"
      },
      "source": [
        "all_texts_copy = all_texts.copy()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "wWqH5vQrrEzn",
        "outputId": "31673604-b16b-4718-f713-1d1d357c0b3c"
      },
      "source": [
        "def tokenize(text):\n",
        "    toks = tokenizer.tokenize(text)\n",
        "    return tensor(tokenizer.convert_tokens_to_ids(toks))\n",
        "\n",
        "tokenized = [tokenize(t) for t in progress_bar(all_texts_copy)]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='950' class='' max='950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [950/950 00:00<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qIQAkbGrer-"
      },
      "source": [
        "class TransformersTokenizer(Transform):\n",
        "    def __init__(self, tokenizer): self.tokenizer = tokenizer\n",
        "    def encodes(self, x): \n",
        "        return x if isinstance(x, Tensor) else tokenize(x)\n",
        "        \n",
        "    def decodes(self, x): return TitledStr(self.tokenizer.decode(x.cpu().numpy()))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUjnkfZkrqLU"
      },
      "source": [
        "tls_copy = TfmdLists(tokenized, TransformersTokenizer(tokenizer), splits=splits, dl_type=LMDataLoader)\n",
        "dls = tls.dataloaders(bs=bs, seq_len=sl)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "4f_t9n7yrw1-",
        "outputId": "9c883401-8ad3-4b63-c19a-59d6854160a0"
      },
      "source": [
        "dls.show_batch(max_n=2)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>text_</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>blackberries for supper.Twinkleberry and six other little squirrels each carried a fat minnow; butHe saw Sif lying asleep. He said, \"I am going to cut off her hair.\"The King of Scots with all his power, cannot turn Arthur of the Bower!\"Mr. McGregor came up with a sieve, which he intended to pop upon theWhen it was noon the ground was all plowed.So Loki went up on the porch and cut off Sif's golden hair.Then Brok showed the hammer. He said, \"This is not a very prettyLoki said, \"You will have to, if we get the hammer back.\"Gretchen thought she was sitting by a big stove. It was so bright.Still Freyja said, \"I will not go.\" And she was very angry. She shookOne day they were playing in the garden.Jason pushed the bulls' heads down to the ground. Then they kicked atThis looks like the end of the story; but it</td>\n",
              "      <td>berries for supper.Twinkleberry and six other little squirrels each carried a fat minnow; butHe saw Sif lying asleep. He said, \"I am going to cut off her hair.\"The King of Scots with all his power, cannot turn Arthur of the Bower!\"Mr. McGregor came up with a sieve, which he intended to pop upon theWhen it was noon the ground was all plowed.So Loki went up on the porch and cut off Sif's golden hair.Then Brok showed the hammer. He said, \"This is not a very prettyLoki said, \"You will have to, if we get the hammer back.\"Gretchen thought she was sitting by a big stove. It was so bright.Still Freyja said, \"I will not go.\" And she was very angry. She shookOne day they were playing in the garden.Jason pushed the bulls' heads down to the ground. Then they kicked atThis looks like the end of the story; but it</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cautiously, peeping round the tree--there was OldNow she thought she could look into a room. In this room was a table.In the evening he came back.They were as high as a big hill. They would come close to each other,He put his head down to the water. What did he see? He saw himself init at anything, it will hit the mark and come back to you.\"They did not want Jason killed. They did not know that the princessThen she put a stick into the pot and leaves grew on it.But Peter, who was very naughty, ran straight away to Mr. McGregor'she could. He said, \"It is little Red Riding-Hood, grandma.\"suit. He walked and walked until he came to Thrym's house. Thrym wasWhen Sif woke up and saw that her hair was gone, she cried andThe next day Jason had to plow with the brass bulls and plant theAnd</td>\n",
              "      <td>, peeping round the tree--there was OldNow she thought she could look into a room. In this room was a table.In the evening he came back.They were as high as a big hill. They would come close to each other,He put his head down to the water. What did he see? He saw himself init at anything, it will hit the mark and come back to you.\"They did not want Jason killed. They did not know that the princessThen she put a stick into the pot and leaves grew on it.But Peter, who was very naughty, ran straight away to Mr. McGregor'she could. He said, \"It is little Red Riding-Hood, grandma.\"suit. He walked and walked until he came to Thrym's house. Thrym wasWhen Sif woke up and saw that her hair was gone, she cried andThe next day Jason had to plow with the brass bulls and plant theAnd Thrym</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Iagd-ZprgU3"
      },
      "source": [
        ""
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NB5oIvvnMl3"
      },
      "source": [
        "## 3. Training (Fine-tuning the model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnXNjN9woKB8"
      },
      "source": [
        "class DropOutput(Callback):\n",
        "    def after_pred(self): self.learn.pred = self.pred[0]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZYWL2UXocmR"
      },
      "source": [
        "If we'd have GPU, we could make use of mixed precision by adding the fp16 flag (to save memory and speed up training time)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3ogXBiZoK5n"
      },
      "source": [
        "learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), cbs=[DropOutput], metrics=[accuracy, Perplexity()]) #.to_fp16()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "2pAwRWO9sHND",
        "outputId": "757311a3-ceeb-4976-f427-3194208f9d66"
      },
      "source": [
        "# Check how good the model is doing with out any fine-tuning step\n",
        "learn.validate()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#3) [4.654792308807373,0.2578125,105.08739471435547]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgN0byZR373X"
      },
      "source": [
        "This lists the validation loss and metrics, perplexity of 105 is pretty bad :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUaz2xDDsHKl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "670dec15-986f-448d-f8b7-245820d39630"
      },
      "source": [
        "learn.lr_find()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SuggestedLRs(lr_min=0.0006309573538601399, lr_steep=0.002511886414140463)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "7EqRXeahsHHV",
        "outputId": "f3807199-da0b-4bcd-f160-a6f0d9440554"
      },
      "source": [
        "learn.fit_one_cycle(3, 1e-3)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.240373</td>\n",
              "      <td>3.819117</td>\n",
              "      <td>0.305779</td>\n",
              "      <td>45.563961</td>\n",
              "      <td>03:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.678046</td>\n",
              "      <td>3.701545</td>\n",
              "      <td>0.311121</td>\n",
              "      <td>40.509865</td>\n",
              "      <td>03:26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.217972</td>\n",
              "      <td>3.740043</td>\n",
              "      <td>0.324621</td>\n",
              "      <td>42.099789</td>\n",
              "      <td>03:12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCssdrDBuVZx"
      },
      "source": [
        "prompt = \"\\n = Dog = \\n \\n Once upon a time there was a magic dog.\""
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcJycmBTh0jM"
      },
      "source": [
        "If we'd have a GPU, we could put everything on cuda:\n",
        "(1) tokens_tensor = tokens_tensor.to('cuda'); \n",
        "(2) model.to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pN4mxJ2G25d2",
        "outputId": "710f592c-b0bf-4f36-ccf8-a1515fcf6505"
      },
      "source": [
        "prompt_ids = tokenizer.encode(prompt)\n",
        "inp = tensor(prompt_ids)[None] #.cuda()\n",
        "inp.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 18])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EChU-JR8WS2"
      },
      "source": [
        "#### (a) Output: beams search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwoFUX60uXXk",
        "outputId": "e50b7958-2728-4246-ee10-5c539f9fba9d"
      },
      "source": [
        "preds = learn.model.generate(inp, max_length=100, num_beams=5, temperature=1.5)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "Lqh-8AZDuXRQ",
        "outputId": "73949f7d-2962-4702-b5e9-54e6325cad65"
      },
      "source": [
        "tokenizer.decode(preds[0].cpu().numpy())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n = Dog = \\n \\n Once upon a time there was a magic dog. It was named Red Riding-Hood. She was so glad to come. She said, \"I will have a good time. I will dress like Freyja, and have a good time. I will dress like Freyja, and have a good time. I will dress like Freyja, and have a good time.\"Then Sindre went to the king and said, \"Give me your head.\"'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExsrXL-c8ajl"
      },
      "source": [
        "#### (b) Ouutput: random sampling search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXsrIkgF-kPh",
        "outputId": "31511ffa-c33d-4d64-804f-a74f80e0ddba"
      },
      "source": [
        "preds = learn.model.generate(inp, do_sample = True, max_length=100, top_k=50, temperature=1.5)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "xFN_S_AZ_Dgv",
        "outputId": "7393d747-7d01-4b2d-8357-64b6a47c005c"
      },
      "source": [
        "tokenizer.decode(preds[0].cpu().numpy())"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n = Dog = \\n \\n Once upon a time there was a magic dog.the gods knew what it mean to him in the name of \"scientifically untied, scufflement from scufflement, scufflement from thein French and the evening, when the wolf got here very early...then sit down to the table to eat: Brok\\'sThe mother duck said, \\'Oh God, we are sobig. But she did not want herthree men on the'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pCzWC4G_WhN"
      },
      "source": [
        "#### (c) Unfreezing to further improve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "fLxFkTzJ_YlK",
        "outputId": "04dcbe62-2be5-46c4-ffeb-410dddb3b5bc"
      },
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(3, 1e-3)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.533128</td>\n",
              "      <td>3.742643</td>\n",
              "      <td>0.314338</td>\n",
              "      <td>42.209415</td>\n",
              "      <td>03:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.344917</td>\n",
              "      <td>3.999513</td>\n",
              "      <td>0.298397</td>\n",
              "      <td>54.571548</td>\n",
              "      <td>03:20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.064552</td>\n",
              "      <td>4.214323</td>\n",
              "      <td>0.305750</td>\n",
              "      <td>67.648354</td>\n",
              "      <td>03:12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98ONHvhk_WS7",
        "outputId": "f7ad3e65-ba8a-47b5-f1fa-a2c95ffca6ec"
      },
      "source": [
        "preds = learn.model.generate(inp, do_sample = True, max_length=100, top_k=50, temperature=1.5)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "GvvvWMNI_Vmx",
        "outputId": "228a2df9-3191-4d09-f0c4-a41e24c366e0"
      },
      "source": [
        "tokenizer.decode(preds[0].cpu().numpy())"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n = Dog = \\n \\n Once upon a time there was a magic dog. AllThe king did not want Jason brought back. His wife would haveHe held the egg in his arms. At last he found a hollow apple.When Thor woke in the morning he went off to lookfor the eagle\\'s claws.He came to the king and said, \"It was a poor little rabbit. But she didstretine.\"But it would take some hard men to get such beautyFrom'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCpeLqvTDAt0"
      },
      "source": [
        "### Part 4: Saving model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HSVnKBFDAOi"
      },
      "source": [
        "path = '/content/gdrive/My Drive/NLP/'"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCFs7AZwDP5K",
        "outputId": "0de428be-023b-42cd-d267-3fbcae72cce8"
      },
      "source": [
        "learn.save(path + 'Model_2')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('/content/gdrive/My Drive/NLP/Model_2.pth')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZFBtkh0nNe_"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQvjtoLXtPHf"
      },
      "source": [
        "### Freezing the encoder\n",
        "n some cases, you might be interested in keeping the weights of the pre-trained encoder frozen and optimizing only the weights of the head layers. To do so, simply set the requires_grad attribute to False on the encoder parameters, which can be accessed with the base_model submodule on any task-specific model in the library:\n",
        "\n",
        "for param in model.base_model.parameters():\n",
        "    param.requires_grad = False\n",
        "https://huggingface.co/transformers/training.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6xWvxpYvDG9"
      },
      "source": [
        "# Optimizing the fine-tuned GPT2-model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjLD9CastTom"
      },
      "source": [
        ""
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "SmRx-rxlwtCx",
        "outputId": "70704bdb-ac2f-4600-9bcf-07c99d31d14e"
      },
      "source": [
        "learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), cbs=[DropOutput], metrics=[Accuracy, Perplexity()]) #.to_fp16()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-daee7b391f2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLearner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCrossEntropyLossFlat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDropOutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPerplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#.to_fp16()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'Accuracy' is not defined"
          ]
        }
      ]
    }
  ]
}
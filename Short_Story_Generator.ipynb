{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Short_Story_Generator_v2.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNMsxuLD1l0nBTTBNLwctFj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frau-web/npl_short_story_generator/blob/main/Short_Story_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nS6NE9eQm6hL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zw6w68Pom7Vs"
      },
      "source": [
        "# Short-Story Generator_v2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4Zo2rXXnEnO"
      },
      "source": [
        "## 1. Loading all libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qipOIbU3ryEP",
        "outputId": "c334fb76-d19b-4085-88da-fe554e8c4d56"
      },
      "source": [
        "#downgrading to Pytorch 1.6 to prevent error, https://forums.fast.ai/t/attributeerror-fakeloader-object-has-no-attribute-persistent-workers/81167/5\n",
        "!pip install torch==1.6.0 torchvision==0.7.0 "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==1.6.0\n",
            "  Using cached https://files.pythonhosted.org/packages/5d/5e/35140615fc1f925023f489e71086a9ecc188053d263d3594237281284d82/torch-1.6.0-cp37-cp37m-manylinux1_x86_64.whl\n",
            "Collecting torchvision==0.7.0\n",
            "  Using cached https://files.pythonhosted.org/packages/4d/b5/60d5eb61f1880707a5749fea43e0ec76f27dfe69391cdec953ab5da5e676/torchvision-0.7.0-cp37-cp37m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.7.0) (7.1.2)\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.6.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastai 2.3.0 has requirement torch<1.8,>=1.7.0, but you'll have torch 1.6.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastai 2.3.0 has requirement torchvision<0.9,>=0.8, but you'll have torchvision 0.7.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.7.1\n",
            "    Uninstalling torch-1.7.1:\n",
            "      Successfully uninstalled torch-1.7.1\n",
            "  Found existing installation: torchvision 0.8.2\n",
            "    Uninstalling torchvision-0.8.2:\n",
            "      Successfully uninstalled torchvision-0.8.2\n",
            "Successfully installed torch-1.6.0 torchvision-0.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Po51UfQnDs8",
        "outputId": "b1dcfa6b-f10a-4744-d2e6-f752b2b0ce14"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "!pip install fastai==2.0.15\n",
        "!pip install fastai2==0.0.30\n",
        "!pip install fastcore==1.0.16\n",
        "\n",
        "\n",
        "from fastai.text.all import *"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fastai==2.0.15\n",
            "  Using cached https://files.pythonhosted.org/packages/98/2e/d4dcc69f67b4557c8543a4c65d3e136b1929b01136b227ceb986e2596825/fastai-2.0.15-py3-none-any.whl\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from fastai==2.0.15) (1.6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fastai==2.0.15) (1.1.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fastai==2.0.15) (2.23.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (from fastai==2.0.15) (2.2.4)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastai==2.0.15) (19.3.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from fastai==2.0.15) (1.4.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from fastai==2.0.15) (7.1.2)\n",
            "Requirement already satisfied: torchvision>=0.7 in /usr/local/lib/python3.7/dist-packages (from fastai==2.0.15) (0.7.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai==2.0.15) (3.2.2)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai==2.0.15) (1.0.0)\n",
            "Requirement already satisfied: fastcore>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from fastai==2.0.15) (1.3.19)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from fastai==2.0.15) (0.22.2.post1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai==2.0.15) (3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastai==2.0.15) (20.9)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->fastai==2.0.15) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->fastai==2.0.15) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai==2.0.15) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai==2.0.15) (2.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==2.0.15) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==2.0.15) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==2.0.15) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==2.0.15) (3.0.4)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai==2.0.15) (1.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy->fastai==2.0.15) (56.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai==2.0.15) (0.8.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai==2.0.15) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai==2.0.15) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai==2.0.15) (3.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai==2.0.15) (4.41.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai==2.0.15) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai==2.0.15) (2.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai==2.0.15) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai==2.0.15) (1.0.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai==2.0.15) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai==2.0.15) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai==2.0.15) (0.10.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fastai==2.0.15) (1.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->fastai==2.0.15) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->fastai==2.0.15) (3.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->fastai==2.0.15) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->fastai==2.0.15) (3.7.4.3)\n",
            "\u001b[31mERROR: fastbook 0.0.16 has requirement fastai>=2.1, but you'll have fastai 2.0.15 which is incompatible.\u001b[0m\n",
            "Installing collected packages: fastai\n",
            "  Found existing installation: fastai 2.3.0\n",
            "    Uninstalling fastai-2.3.0:\n",
            "      Successfully uninstalled fastai-2.3.0\n",
            "Successfully installed fastai-2.0.15\n",
            "Requirement already satisfied: fastai2==0.0.30 in /usr/local/lib/python3.7/dist-packages (0.0.30)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (1.1.5)\n",
            "Requirement already satisfied: torchvision>=0.7 in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (0.7.0)\n",
            "Requirement already satisfied: fastcore>=0.1.34 in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (1.3.19)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (2.23.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (3.13)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (1.4.1)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (1.0.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (1.6.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (2.2.4)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (19.3.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (7.1.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai2==0.0.30) (1.19.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai2==0.0.30) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai2==0.0.30) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai2==0.0.30) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai2==0.0.30) (1.3.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai2==0.0.30) (2018.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastai2==0.0.30) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fastai2==0.0.30) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastai2==0.0.30) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastai2==0.0.30) (1.24.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fastai2==0.0.30) (1.0.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->fastai2==0.0.30) (0.16.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai2==0.0.30) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai2==0.0.30) (3.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai2==0.0.30) (2.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai2==0.0.30) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai2==0.0.30) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai2==0.0.30) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai2==0.0.30) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai2==0.0.30) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai2==0.0.30) (4.41.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy->fastai2==0.0.30) (56.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai2==0.0.30) (0.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->fastai2==0.0.30) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->fastai2==0.0.30) (3.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->fastai2==0.0.30) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->fastai2==0.0.30) (3.7.4.3)\n",
            "Collecting fastcore==1.0.16\n",
            "  Using cached https://files.pythonhosted.org/packages/99/c9/bd299caa1f1c002495bc9ffb98d31605e78a131a2ba3ba66a2682a7ab245/fastcore-1.0.16-py3-none-any.whl\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastcore==1.0.16) (20.9)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastcore==1.0.16) (19.3.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->fastcore==1.0.16) (2.4.7)\n",
            "\u001b[31mERROR: nbdev 1.1.14 has requirement fastcore>=1.3.19, but you'll have fastcore 1.0.16 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastrelease 0.1.11 has requirement fastcore>=1.3.13, but you'll have fastcore 1.0.16 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastbook 0.0.16 has requirement fastai>=2.1, but you'll have fastai 2.0.15 which is incompatible.\u001b[0m\n",
            "Installing collected packages: fastcore\n",
            "  Found existing installation: fastcore 1.3.19\n",
            "    Uninstalling fastcore-1.3.19:\n",
            "      Successfully uninstalled fastcore-1.3.19\n",
            "Successfully installed fastcore-1.0.16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifqfSmBsm-GT",
        "outputId": "0244528e-0afb-4f27-a58b-1a1452e167d3"
      },
      "source": [
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()\n",
        "\n",
        "from fastbook import *\n",
        "from IPython.display import display,HTML"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.7.1 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWZmfwVHnXsm",
        "outputId": "fa07e17b-fc02-48cc-a160-cb0c1250214f"
      },
      "source": [
        "!pip install tokenizers\n",
        "!pip install transformers #!pip install -Uq transformers"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.7/dist-packages (0.10.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6DhKQ-TnitZ"
      },
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2TokenizerFast"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gx9_ctBno00"
      },
      "source": [
        "pretrained_weights = 'gpt2'\n",
        "tokenizer = GPT2TokenizerFast.from_pretrained(pretrained_weights)\n",
        "model = GPT2LMHeadModel.from_pretrained(pretrained_weights)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3qjWcKqnJg5"
      },
      "source": [
        "## 2. Loading Preprocessing Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2O9EDHECnMJe"
      },
      "source": [
        "# Import the data\n",
        "gist = \"https://gist.githubusercontent.com/frau-web/84b7a2155e97d479db0ca91b6fc3a0db/raw/89460c734dd7ba87ae6e6b4c4ffaebfa2f8f2f81/shortstories.txt\"\n",
        "df = pd.read_csv(gist, sep='\\t', header=None) \n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7TQTa1hqKQP"
      },
      "source": [
        "# Split into test and train\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_test_ratio = 0.9\n",
        "#train_valid_ratio = 7/9\n",
        "df_full_train, df_test = train_test_split(df, train_size = train_test_ratio, random_state = 1)\n",
        "#df_train, df_valid = train_test_split(df_full_train, train_size = train_valid_ratio, random_state = 1)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gAj0HvVp9Fk"
      },
      "source": [
        "# We gather all texts in one numpy array (since it will be easier to use this way with fastai)\n",
        "all_texts = np.concatenate([df_full_train[0].values, df_test[0].values])\n",
        "#all_texts"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjfOEDE0n0fO"
      },
      "source": [
        "# To process this data to train a model, we need to build a Transform that will be applied lazily.\n",
        "\n",
        "class TransformersTokenizer(Transform):\n",
        "    def __init__(self, tokenizer): self.tokenizer = tokenizer\n",
        "    def encodes(self, x): \n",
        "        toks = self.tokenizer.tokenize(x)\n",
        "        return tensor(self.tokenizer.convert_tokens_to_ids(toks))\n",
        "    def decodes(self, x): return TitledStr(self.tokenizer.decode(x.cpu().numpy()))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQGboXNApZYM"
      },
      "source": [
        "\n",
        "\n",
        "Two comments on the code above:\n",
        "- in encodes we don't use the tokenizer.encode method since it does some additional preprocessing for the model after tokenizing and numericalizing (the part throwing a warning before). Here we don't need any post-processing so it's fine to skip it.\n",
        "- in decodes we return a TitledStr object and not just a plain string. That's a fastai class that adds a show method to the string, which will allow us to use all the fastai show methods.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KafNA1LvpVn-"
      },
      "source": [
        "splits = [range_of(df_full_train), list(range(len(df_full_train), len(all_texts)))]\n",
        "tls = TfmdLists(all_texts, TransformersTokenizer(tokenizer), splits=splits, dl_type=LMDataLoader)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnoGOTrqqvaA",
        "outputId": "348398cc-4d28-485d-b9e3-c4995afa46a5"
      },
      "source": [
        "tls.train[0],tls.valid[0]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1026,  373,  355, 4692,  379, 1363,  355,  287,  262, 4675,   13, 1119,  547, 1165, 3595,  284,  423]),\n",
              " tensor([  464,  6175,  2227,   284,   307,   588,   262, 11858,    13,  1406,   339,   531,   284, 31771,    11,   366,    40,   481]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8U14f9kq1jG",
        "outputId": "b30680ab-71ac-4d3f-cd95-fe53c1f9b08f"
      },
      "source": [
        "show_at(tls.train, 0)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "It was as cold at home as in the street. They were too poor to have\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gnNVCKuq9vh"
      },
      "source": [
        "The fastai library expects the data to be assembled in a DataLoaders object (something that has a training and validation dataloader). We can get one by using the dataloaders method. We just have to specify a batch size and a sequence length. We'll train with sequences of size 256 (GPT2 used sequence length 1024, but not everyone has enough GPU RAM for that):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fXhPuQBq_DO"
      },
      "source": [
        "bs,sl = 4,256\n",
        "dls = tls.dataloaders(bs=bs, seq_len=sl)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "X25EPI8zrEhW",
        "outputId": "204a0358-4177-4240-cf44-a1ef1b379e76"
      },
      "source": [
        "dls.show_batch(max_n=2)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>text_</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tool-shed, perhaps hidden underneath a flower-pot. He began to turnAll the gods came around to see. Then Loki came up to show his things.So Brok blew as hard as he could.happened, he came out, and climbed upon a wheelbarrow and peeped over.step--pit pat, paddle pat! pit pat, waddle pat!Nutkin began again \"Arthur O'Bower has broken his band, he comes roaring up the land!When Sif woke up and saw that her hair was gone, she cried andwill fly up to Thor's house and get the hammer.\"The wolf ran off and took a short way, but Red Riding-Hood stopped toOn the third day the squirrels got up very early and went fishing; theyWhen Red Riding-Hood tapped on the door, the wolf called out, \"Who isanimals.He lost one of his shoes among the cabbages, and the other shoeThey cut at the Harpies but could not hurt them.to Owl Island to gather nuts.Just then</td>\n",
              "      <td>-shed, perhaps hidden underneath a flower-pot. He began to turnAll the gods came around to see. Then Loki came up to show his things.So Brok blew as hard as he could.happened, he came out, and climbed upon a wheelbarrow and peeped over.step--pit pat, paddle pat! pit pat, waddle pat!Nutkin began again \"Arthur O'Bower has broken his band, he comes roaring up the land!When Sif woke up and saw that her hair was gone, she cried andwill fly up to Thor's house and get the hammer.\"The wolf ran off and took a short way, but Red Riding-Hood stopped toOn the third day the squirrels got up very early and went fishing; theyWhen Red Riding-Hood tapped on the door, the wolf called out, \"Who isanimals.He lost one of his shoes among the cabbages, and the other shoeThey cut at the Harpies but could not hurt them.to Owl Island to gather nuts.Just then</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>,Peter scuttered underneath the bushes. But presently, as nothingThen the same fly came in and bit him again.kill Jason.down like a little red cherry, singing \"Riddle me, riddle me, rot-tot-tote! He said to Brok, \"Now blow as hard as you can.\"How big your ears are, grandma.Her feet were bare. When she left home, she had on some big slippersThen Loki said, \"I can't stand this. I will get the apples for you.\"Then Sindre put a lump of iron into the fire.Peter gave himself up for lost, and shed big tears; but his sobs wereGretchen got colder and colder.a Christmas tree. Very many candles were on the tree. It was fulltied was not far off.duckling.There on the grass was a fine large sheep. This sheep had a fleece ofAnd Sindre went out. Brok blew and blew. The same mean fly came again,By and by he grew tame and let the children</td>\n",
              "      <td>Peter scuttered underneath the bushes. But presently, as nothingThen the same fly came in and bit him again.kill Jason.down like a little red cherry, singing \"Riddle me, riddle me, rot-tot-tote! He said to Brok, \"Now blow as hard as you can.\"How big your ears are, grandma.Her feet were bare. When she left home, she had on some big slippersThen Loki said, \"I can't stand this. I will get the apples for you.\"Then Sindre put a lump of iron into the fire.Peter gave himself up for lost, and shed big tears; but his sobs wereGretchen got colder and colder.a Christmas tree. Very many candles were on the tree. It was fulltied was not far off.duckling.There on the grass was a fine large sheep. This sheep had a fleece ofAnd Sindre went out. Brok blew and blew. The same mean fly came again,By and by he grew tame and let the children</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2san9ANrTKZ"
      },
      "source": [
        "### - Alternative\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ol-p4tNrX9_"
      },
      "source": [
        "Another way to gather the data is to preprocess the texts once and for all and only use the transform to decode the tensors to texts:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1jDD-_KrYjC"
      },
      "source": [
        "all_texts_copy = all_texts.copy()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "wWqH5vQrrEzn",
        "outputId": "4b9cb7a4-d6e7-4459-e603-9732a75cf391"
      },
      "source": [
        "def tokenize(text):\n",
        "    toks = tokenizer.tokenize(text)\n",
        "    return tensor(tokenizer.convert_tokens_to_ids(toks))\n",
        "\n",
        "tokenized = [tokenize(t) for t in progress_bar(all_texts_copy)]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='950' class='' max='950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [950/950 00:00<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qIQAkbGrer-"
      },
      "source": [
        "class TransformersTokenizer(Transform):\n",
        "    def __init__(self, tokenizer): self.tokenizer = tokenizer\n",
        "    def encodes(self, x): \n",
        "        return x if isinstance(x, Tensor) else tokenize(x)\n",
        "        \n",
        "    def decodes(self, x): return TitledStr(self.tokenizer.decode(x.cpu().numpy()))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUjnkfZkrqLU"
      },
      "source": [
        "tls_copy = TfmdLists(tokenized, TransformersTokenizer(tokenizer), splits=splits, dl_type=LMDataLoader)\n",
        "dls = tls.dataloaders(bs=bs, seq_len=sl)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "4f_t9n7yrw1-",
        "outputId": "51c508a1-5dea-44d4-c06c-35c472ace96d"
      },
      "source": [
        "dls.show_batch(max_n=2)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>text_</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>blackberries for supper.Twinkleberry and six other little squirrels each carried a fat minnow; butHe saw Sif lying asleep. He said, \"I am going to cut off her hair.\"The King of Scots with all his power, cannot turn Arthur of the Bower!\"Mr. McGregor came up with a sieve, which he intended to pop upon theWhen it was noon the ground was all plowed.So Loki went up on the porch and cut off Sif's golden hair.Then Brok showed the hammer. He said, \"This is not a very prettyLoki said, \"You will have to, if we get the hammer back.\"Gretchen thought she was sitting by a big stove. It was so bright.Still Freyja said, \"I will not go.\" And she was very angry. She shookOne day they were playing in the garden.Jason pushed the bulls' heads down to the ground. Then they kicked atThis looks like the end of the story; but it</td>\n",
              "      <td>berries for supper.Twinkleberry and six other little squirrels each carried a fat minnow; butHe saw Sif lying asleep. He said, \"I am going to cut off her hair.\"The King of Scots with all his power, cannot turn Arthur of the Bower!\"Mr. McGregor came up with a sieve, which he intended to pop upon theWhen it was noon the ground was all plowed.So Loki went up on the porch and cut off Sif's golden hair.Then Brok showed the hammer. He said, \"This is not a very prettyLoki said, \"You will have to, if we get the hammer back.\"Gretchen thought she was sitting by a big stove. It was so bright.Still Freyja said, \"I will not go.\" And she was very angry. She shookOne day they were playing in the garden.Jason pushed the bulls' heads down to the ground. Then they kicked atThis looks like the end of the story; but it</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cautiously, peeping round the tree--there was OldNow she thought she could look into a room. In this room was a table.In the evening he came back.They were as high as a big hill. They would come close to each other,He put his head down to the water. What did he see? He saw himself init at anything, it will hit the mark and come back to you.\"They did not want Jason killed. They did not know that the princessThen she put a stick into the pot and leaves grew on it.But Peter, who was very naughty, ran straight away to Mr. McGregor'she could. He said, \"It is little Red Riding-Hood, grandma.\"suit. He walked and walked until he came to Thrym's house. Thrym wasWhen Sif woke up and saw that her hair was gone, she cried andThe next day Jason had to plow with the brass bulls and plant theAnd</td>\n",
              "      <td>, peeping round the tree--there was OldNow she thought she could look into a room. In this room was a table.In the evening he came back.They were as high as a big hill. They would come close to each other,He put his head down to the water. What did he see? He saw himself init at anything, it will hit the mark and come back to you.\"They did not want Jason killed. They did not know that the princessThen she put a stick into the pot and leaves grew on it.But Peter, who was very naughty, ran straight away to Mr. McGregor'she could. He said, \"It is little Red Riding-Hood, grandma.\"suit. He walked and walked until he came to Thrym's house. Thrym wasWhen Sif woke up and saw that her hair was gone, she cried andThe next day Jason had to plow with the brass bulls and plant theAnd Thrym</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Iagd-ZprgU3"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NB5oIvvnMl3"
      },
      "source": [
        "## 3. Training (Fine-tuning the model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnXNjN9woKB8"
      },
      "source": [
        "class DropOutput(Callback):\n",
        "    def after_pred(self): self.learn.pred = self.pred[0]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3ogXBiZoK5n"
      },
      "source": [
        "learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), cbs=[DropOutput], metrics=Perplexity()) #.to_fp16()"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "2pAwRWO9sHND",
        "outputId": "282332b1-9257-4329-822d-ac418f072606"
      },
      "source": [
        "learn.validate()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [4.648604393005371,104.43912506103516]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgN0byZR373X"
      },
      "source": [
        "This lists the validation loss and metrics, perplexity of 105 is pretty bad :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUaz2xDDsHKl"
      },
      "source": [
        "#learn.lr_find()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "7EqRXeahsHHV",
        "outputId": "23933790-101f-46fd-9abb-868e4ce7791a"
      },
      "source": [
        "learn.fit_one_cycle(3, 1e-3)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.253866</td>\n",
              "      <td>4.414801</td>\n",
              "      <td>82.665359</td>\n",
              "      <td>02:59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.310469</td>\n",
              "      <td>4.673801</td>\n",
              "      <td>107.104118</td>\n",
              "      <td>03:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.211378</td>\n",
              "      <td>5.010121</td>\n",
              "      <td>149.922852</td>\n",
              "      <td>03:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCssdrDBuVZx"
      },
      "source": [
        "prompt = \"\\n = Dog = \\n \\n Once upon a time there was a magic dog.\""
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pN4mxJ2G25d2",
        "outputId": "3d104a13-f5e6-426d-c5ec-22f54914b996"
      },
      "source": [
        "prompt_ids = tokenizer.encode(prompt)\n",
        "inp = tensor(prompt_ids)[None] #.cuda()\n",
        "inp.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 18])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EChU-JR8WS2"
      },
      "source": [
        "#### (a) Output: beams search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwoFUX60uXXk",
        "outputId": "77538c8f-70c9-4b02-e839-07a73eb65ef3"
      },
      "source": [
        "preds = learn.model.generate(inp, max_length=100, num_beams=5, temperature=1.5)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "Lqh-8AZDuXRQ",
        "outputId": "25c8892c-f19c-4a7a-d605-6c941cba8ae3"
      },
      "source": [
        "tokenizer.decode(preds[0].cpu().numpy())"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n = Dog = \\n \\n Once upon a time there was a magic dog. He was named Red Riding-Hood.Then the gods said, \"You may have it, if you will give me the golden fleece.\"Then Sindre went to the king and said, \"Mr. McGregor, you may have it, if you will give me the golden fleece.\"The gods said, \"Yes, I will.\"They said, \"He is a very ugly duck. He'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExsrXL-c8ajl"
      },
      "source": [
        "#### (b) Ouutput: random sampling search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXsrIkgF-kPh",
        "outputId": "92bbbb8b-4204-40c9-fb4a-42ecd621b3e0"
      },
      "source": [
        "preds = learn.model.generate(inp, do_sample = True, max_length=100, top_k=50, temperature=1.5)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "xFN_S_AZ_Dgv",
        "outputId": "d34b1927-16ce-4ef8-d128-a5b98b42db0b"
      },
      "source": [
        "tokenizer.decode(preds[0].cpu().numpy())"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n = Dog = \\n \\n Once upon a time there was a magic dog.The girl did not have time till the morning.Old Brown said, \"Just give me one night.\"But the eagle said, \"Yes…. They do.\"THE LITTLE THOR GOT SHOROHOOD THOR GOT SHOROOT, they called the eagle \"Thor!\" And Peter blew and smoke and smoke from his nostrils.Loki felt rather glad at least bit him.he did'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pCzWC4G_WhN"
      },
      "source": [
        "#### (c) Unfreezing to further improve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "fLxFkTzJ_YlK",
        "outputId": "d27df2cf-f080-453f-eff1-5cf52ff07fdb"
      },
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(3, 1e-3)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.440275</td>\n",
              "      <td>3.767107</td>\n",
              "      <td>43.254726</td>\n",
              "      <td>02:39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.326565</td>\n",
              "      <td>3.945486</td>\n",
              "      <td>51.701439</td>\n",
              "      <td>02:55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.092449</td>\n",
              "      <td>4.219459</td>\n",
              "      <td>67.996658</td>\n",
              "      <td>02:49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.843688</td>\n",
              "      <td>4.701869</td>\n",
              "      <td>110.152855</td>\n",
              "      <td>02:47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.635963</td>\n",
              "      <td>4.648604</td>\n",
              "      <td>104.439125</td>\n",
              "      <td>03:13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98ONHvhk_WS7",
        "outputId": "e09c07c5-a709-4f79-bf1b-f5440e2bd36a"
      },
      "source": [
        "preds = learn.model.generate(inp, do_sample = True, max_length=100, top_k=50, temperature=1.5)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "GvvvWMNI_Vmx",
        "outputId": "424f9fff-2189-480f-8d96-1caf23a29e99"
      },
      "source": [
        "tokenizer.decode(preds[0].cpu().numpy())"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n = Dog = \\n \\n Once upon a time there was a magic dog. She could go anywhereand took them back to him at anything.The king glad they had gold leaves, because she was so gladThor said, \"Good evening, Idun has a golden crown that may beHe sent his men in ships to take Jason, but they could not get him.One can only a king and six legs haveTo some one. He is very beautiful.\"At last he said,'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCpeLqvTDAt0"
      },
      "source": [
        "### Part 4: Saving model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HSVnKBFDAOi"
      },
      "source": [
        "path = '/content/gdrive/My Drive/NLP/'"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCFs7AZwDP5K",
        "outputId": "dc544a81-0798-4dfe-dfe8-68fc9611ae1c"
      },
      "source": [
        "learn.save(path + 'Model_2')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('/content/gdrive/My Drive/NLP/Model_2.pth')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZFBtkh0nNe_"
      },
      "source": [
        ""
      ]
    }
  ]
}